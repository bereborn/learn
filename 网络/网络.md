# 网络

---

- **OSI，TCP/IP，五层协议的体系结构**
1. OSI分层（7层）：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层
2. TCP/IP分层（4层）：网络接口层、网际层、运输层、应用层
3. 五层协议（5层）：物理层、数据链路层、网络层、运输层、应用层

- **每一层的协议**
1. 物理层：RJ45、CLOCK、IEEE802.3（中继器，集线器，网关）
2. 数据链路：PPP、FR、HDLC、VLAN、MAC（网桥，交换机）
3. 网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP（路由器）
4. 传输层：TCP、UDP、SPX
5. 会话层：NFS、SQL、NETBIOS、RPC
6. 表示层：JPEG、MPEG、ASII
7. 应用层：FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS

- **IP地址**
1. 网络号 + 主机号   

概念 | 网络范围 | 默认掩码 | 作用
-----|----------|----------|-----
A类地址，以0开始 | 0-127.x.x.x | 255.0.0.0/8 | 
B类地址，以10开始 | 128-191.x.x.x | 255.255.0.0/16 |
C类地址，以110开始 | 192-y.x.x.x | 255.255.255.0/24 |
D类地址，以1110开始 |            |                  | 用于组播
E类地址，以11110开始 |            |                  | 科研保留

2. 子网掩码   
(1)判断两个IP在不在一个局域网内部   
(2)子网掩码可以看出有多少位是网络号，有多少位是主机号
3. 网关：一个IP网络通向另一个IP网络
4. 广播地址：专门用于同时向网络中所有主机进行发送的一个地址

- **地址解析协议ARP**
1. 每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关
2. 当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机IP地址，源主机MAC地址，目的主机的IP地址
3. 当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址
4. 源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败

- **ICMP协议（基于IP协议）**
1. ICMP两类：一类是差错报文，一类是查询报文
2. ICMP报文格式：| 8位类型 | 8位代码 | 16位校验和 |，8位类型字段和8位代码字段共同决定一种ICMP报文的类型
3. ICMP协议功能：确认IP包是否成功到达目标地址以及通知在发送过程中IP包被丢弃的原因
4. Tracert 命令用 IP 生存时间 (TTL) 字段和 ICMP 错误消息来确定从一个主机到网络上其他主机的路由   
(1)首先，tracert送出一个TTL是1的IP数据包到目的地，当路径上的第一个路由器收到这个数据包时，它将TTL减1   
(2)TTL变为0，所以该路由器会将此数据包丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址）   
(3)tracert 每次将送出的数据包的TTL加1来发现另一个路由器，这个重复的动作一直持续到某个数据包抵达目的地   
(4)当数据包到达目的地后，该主机则不会送回ICMP time exceeded消息，一旦到达目的地，由于tracert通过UDP数据包向不常见端口(30000以上)发送数据包，因此会收到「ICMP port unreachable」消息，故可判断到达目的地
5. ping 用来检查网络是否通畅或者网络连接速度的命令   
(1)Ping主要是两个特定的ICMP消息，ECHO_REQUEST 和 ECHO_REPLY，通过比较当前时间与报文时间计算出耗费时间，如果没有收到符合该sequence number的报文，则认为该报文丢失   
(2)反馈信息：Request timed out/Destination host Unreachable/Bad IP address/Unknown host/No answer

- **IP协议**
1. IP报文格式：| 4位版本 | 4为首部长度 | 8位服务类型（TOS） | 16位总长度 | 16位标示 | 3位标志 | 13位片偏移 | 8位生存时间（TTl） | 8位协议 | 16位首部校验和 | 32位源IP地址 | 32位目的IP地址 | 选项 | 数据   
(1)4位版本：标识目前采用的IP协议的版本号     
(2)4位首部长度：用于标识首部的长度   
(3)8位服务类型：包括3bit的优先权字段（已被忽略），4bit的TOS字段，1bit的始终为0的未使用位，只有网络设备能够支持识别ToS字段时，这给字段设置才有意义   
&emsp;a)最小延迟，对应于对延迟敏感的应用，如telnet和人login等   
&emsp;b)最大吞吐量，对应于对吞吐量要求比较高的应用，如FTP文件应用，对文件传输吞吐量有比较高的要求   
&emsp;c)最高可靠性，对网络传输可靠性要求高的应用，如使用SNMP的应用、路由协议等等   
&emsp;d)最小费用，如NNTP这种用户网络新闻等   
(4)6位总长度(字节数)：整个IP数据报的长度   
(5)16位标识：唯一地标识主机发送的每一份数据报，IP数据报的最大长度可达65535字节，但大多数链路层都会对它进行分片。由于TCP本身会把用户数据分成若干片，因此这个字段一般来说不会影响到TCP   
(6)3位标志：用于IP数据报分片，该字段第1bit不使用，第2bit是DF(Don't Fragment)位，DF位设为1时表明IP不对该数据包分片。第3bit是MF(More Fragments)位，当对数据包分片时，除了最后一片外，其他每个组成数据报的片都要把此位设为1   
(7)13位偏移：用于IP数据报分片，单位为8字节，表示该片相对于原始数据报开始处的位置，能表示的最大偏移为2^13*8=65536字节   
(8)8位生存时间(TTL)：设置数据报可以经过的最多路由器数量，每经过一个路由器，该值就减去1，当该值为0时，数据报就被丢弃
(9)8位协议：表示上层传输层所用的协议类型，1表示ICMP协议，2表示IGMP协议，6表示TCP协议，17表示UDP协议
(10)16位首部校验和：用于对IP首部的正确性进行校验，但不包括数据部分，这点不同于TCP和UDP的首部校验和

> [计算机网络基础知识总结](https://www.cnblogs.com/maybe2030/p/4781555.html#_label3)   
> [计算机网络基础知识](https://www.cnblogs.com/xdyixia/p/9275246.html)

---
## UDP

- **UDP协议**
1. UDP报文格式：| 来源端口 | 目的端口 | 报文长度 | 检验和 |
2. 应用场景：域名系统（DNS）、  动态主机配置协议（DHCP）、流媒体、即时多媒体游戏和IP电话（VoIP）


---
## TCP

- **TCP报文格式**
1. TCP报文格式：| 16位源端口号 | 16位目的端口号 | 32位序号 | 32位确认序号 | 4位首部长度 | 保留（6位） | 6位标志位 | 16位窗口大小 | 16位校验和 | 16为紧急指针 | 选项 | 数据   
(1)32位序列号：序列号用来标识从TCP发送端已经发送的字节数，达到最大值232−1之后，再从0开始   
(2)32位确认序列号：确认序列号用来标识TCP接收端期望接收的下一个序列号（反过来想也就是，TCP接收端已经接受到的字节数为确认序列号减去1），只有ACK标志位为1时，该字段才有效   
(3)6位标志位：URG 标记后面的"16位紧急指针"是否有效 | ACK 标记前面的"32位确认序号"是否有效 | PSH 接收方应该尽快的将这个报文交给上层的网络层 | RST 重建连接 | SYN 标记这个TCP段是用来同步初始序号（ISN）的 | FIN 标记发送端已经完成了发送任务   
(4)16位窗口大小：窗口大小为字节数，用于TCP的流量控制，这个值是接收端期望接受的字节数   
(5)16位紧急指针：只有前面提到的URG标记位为1时，这个字段才有效   

- **三次握手与四次挥手**
1. 为什么需要三次握手：假设两次即可握手，服务端在收到客户端的SYN并且回复SYN+AKC之后，就认为连接已经建立完成了，并为之分配相应的资源，但客户机却因为网络延迟等问题一直没收到服务端回复的SYN+ACK，这样客户端就认为连接没有建立成功，糟糕的是，客户端会因为连接没有成功而不停的重试，这样每次服务端都会认为连接建立成功并分配资源，就会造成服务端资源极大的浪费
2. 为什么需要四次挥手：为了让"被动断开方"有机会将想要发送的数据发送完，主动断开方在发送完FIN并收到了ACK确认信息进入FIN_WAIT_2状态后，只关闭了发送功能了，但仍然保留接收功能，这样"被动断开方"就有机会将没有发送完的数据发送完成，发送完成之后，"被动断开方"也发送一个FIN，相当于告诉"主动断开方"：我的数据已经发完了，以后不会再发数据了，你可以安心的把接收功能关闭了，另外我自己也要关闭了
3. TIME_WAIT作用："主动断开的一方"在发送完最后一次ACK后进入的等待状态，确保"被动断开连接端"可以收到ACK确认消息，TIME_WAIT = 2*MSL（Maximum Segment Lifetime 报文的最大生存时间），同时保证任何迟到的报文被丢弃，不会影响到下一次新建立的连接

- **TCP可靠传输**
1. 数据被分割成TCP认为最适合发送的数据块
2. 自适应的超时及重传策略：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段，如果不能及时收到一个确认，将重发这个报文段
3. 延迟确认：当TCP收到发自TCP连接另一端的数据，它将发送一个确认，这个确认不是立即发送，通常将推迟几分之一秒
4. TCP将保持它首部和数据的检验和：检测数据在传输过程中的任何变化，如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段
5. 重新排序：TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层
6. 丢弃重复数据：IP数据报会发生重复，TCP的接收端必须丢弃重复的数据
7. 流量控制：TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这将防止较快主机致使较慢主机的缓冲区溢出

- **TCP 序列号 和 确认号**
1. 序列号被用来跟踪该端发送的数据量，每一个包中都包含序列号，在接收端则通过确认号用来通知发送端数据成功接收
2. 当某个主机开启一个TCP会话时，他的初始序列号（ISN）是随机的，随机序号防止攻击者利用相同ip地址和端口以及合适的序号进行恶意攻击（RFC793中建议ISN和一个假的时钟绑在一起，这个时钟会在每4微秒对ISN做加一操作，直到超过2^32，又从0开始，这需要4小时才会产生ISN的回绕问题，这几乎可以保证每个新连接的ISN不会和旧的连接的ISN产生冲突）

```
固定初始化序列号产生的问题：
1. 假设ISN固定是1，Client和Server建立好一条TCP连接后，Client连续给Server发了10个包，这10个包不知怎么被链路上的路由器缓存了，这个时候碰巧Client挂掉了
2. 然后Client用同样的端口号重新连上Server，Client又连续给Server发了几个包，假设这个时候Client的序列号变成了5
3. 接着，之前被路由器缓存的10个数据包全部被路由到Server端了，Server给Client回复确认号10，这个时候，Client整个都不好了，这是什么情况？我的序列号才到5，你怎么给我的确认号是10了，整个都乱了
```

3. SYN标志位和FIN标志位要占1位确认序号
4. 序列号为当前端成功发送并且收到确认序号的数据位数，确认号为当前端成功接收的数据位数

- **TCP最大报文长度**
1. 最大报文段长度（MSS）表示TCP传往另一端的最大块数据的长度
2. 当一个连接建立时，连接的双方都要通告各自的MSS（MSS选项只能出现在SYN报文段中），另一端的主机收到了一个连接请求，它能将MSS值设置为外出接口上的MTU长度减去固定的IP首部和TCP首部长度（MTU是数据链路层最大传输单元），避免IP分片
3. 但主机两端连接以太网，以太网中间采用其他MTU，也将出现IP分片，使用路径上的MTU发现机制解决问题
4. MTU：以太网Ethernet最大的数据帧是1518字节，以太网帧的帧头14字节和帧尾CRC校验4字节（共占18字节），剩下承载上层协议的地方也就是Data域最大就只剩1500字节
5. MSS：MSS（1460） = MTU（1500） - 20（IP数据包包头的大小） - 20（TCP数据段的包头），实际场景下：TCP包头中会带有12字节的选项----时间戳，MSS（1448） = MSS（1460）- 32（12字节的时间戳）

- **复位报文段**
1. TCP socket在任何状态下，只要收到RST包，即可进入CLOSED初始状态
2. RST发送场景：   
(1)到不存在的端口，使用复位报文段（UDP产生一个ICMP端口不可达的信息）   
(2)异常终止一个连接，异常终止一个连接对应用程序来说有两个优点：一个是丢弃任何待发数据并立即发送复位报文段，另一个是RST的接收方会区分另一端执行的是异常关闭还是正常关闭   
(3)检测半关闭连接，如果一方已经关闭或异常终止连接而另一方却还不知道，我们将这样的TCP连接称为半打开的，服务器重启处于半关闭连接，丢失复位前连接的所有信息，收到客户端的报文后以复位作为应答   
(4)close(sockfd)时，直接丢弃接收缓冲区未读取的数据，并给对方发一个RST

- **同时打开，同时关闭**
1. 同时打开，TCP是特意设计为了可以处理同时打开，对于同时打开它仅建立一条连接而不是两条连接
2. 同时关闭，FIN_WAIT_1 --- CLOSING --- TIME_WAIT

- **TCP选项字段**
1. kind=0，选项表结束（EOP）选项，放在末尾用于填充
2. kind=1，空操作（NOP）选项，一般用于将TCP选项的总长度填充为4字节的整数倍
3. kind=2，最大报文段长度（MSS）选项，TCP模块通常将MSS设置为（MTU-40）字节
4. kind=3，窗口扩大因子选项，TCP连接初始化时，通信双方使用该选项来协商接收窗口的扩大因子，TCP头部中的接收通告窗口大小是N，窗口扩大因子（移位数）是M，那么TCP报文段的实际接收通告窗口大小是N*2M，或者说N左移M位
5. kind=4，选择性确认（Selective Acknowledgment，SACK）选项，TCP通信时，如果某个TCP报文段丢失，则TCP会重传最后被确认的TCP报文段后续的所有报文段，这样原先已经正确传输的TCP报文段也可能重复发送，从而降低了TCP性能，SACK使TCP只重新发送丢失的TCP报文段，选择性确认选项用在连接初始化时，表示是否支持SACK技术
6. kind=5，SACK实际工作的选项，该选项的参数告诉发送方本端已经收到并缓存的不连续的数据块，从而让发送端可以据此检查并重发丢失的数据块，每个块边沿（edge of block）参数包含一个4字节的序号，其中块左边沿表示不连续块的第一个数据的序号，而块右边沿则表示不连续块的最后一个数据的序号的下一个序号，这样一对参数（块左边沿和块右边沿）之间的数据是没有收到的
7. kind=8，时间戳选，提供了较为准确的计算通信双方之间的回路时间（Round Trip Time，RTT）的方法，从而为TCP流量控制提供重要信息

- **TCP 5 元祖**
1. 本地IP地址、本地端口号、远端IP地址和远端端口号、传输协议，无论何时关闭一个连接，一端必须保持这个连接，我们看到TIME_WAIT状态将处理这个问题，处理的原则是执行主动打开的一端在进入这个状态时要保持的时间为TCP实现中规定的MSL值的两倍

- **TCP请求队列**
1. 正等待连接请求的一端有一个固定长度的连接队列，该队列中的连接已被TCP接受（即三次握手已经完成），但还没有被应用层所接受
2. 应用层将指明该队列的最大长度，这个值通常称为积压值(backlog)，它的取值范围是0~5之间的整数
3. 如果对于新的连接请求，该TCP监听的端点的连接队列中还有空间，TCP模块将对SYN进行确认并完成连接的建立，但应用层只有在三次握手中的第三个报文段收到后才会知道这个新连接时，另外，当客户进程的主动打开成功但服务器的应用层还不知道这个新的连接时，它可能会认为服务器进程已经准备好接收数据了（如果发生这种情况，服务器的TCP仅将接收的数据放入缓冲队列)
4. 如果对于新的连接请求，连接队列中已没有空间，TCP将不理会收到的SYN，也不发回任何报文段（即不发回RST），服务器程序迫使客户TCP随后重传SYN，以等待连接队列有空间接受新的连接

- **TCP 之 Listen**
1. TCP socket分监听socket和传输socket两种：   
(1)监听socket：负责处理网络上来的连接请求   
(2)传输socket：负责在网络上的两个端点之间传输TCP数据   
(3)pending socket：是某客户端的syn包到达，内核为这个syn包对应的tcp请求生成一个socket，但是此时三次握手并没有完成
2. 内核为每个tcp服务器维护两个socket队列：pending socket队列和已建立连接的socket队列，backlog这个参数用来决定 pending socket队列的长度，有个映射关系，0表示长度可以无限大
3. pending socket 队列两种可能：   
(1)客户端响应了服务器的syn（第三个ack到达），第三次握手结束，内核触发accept函数执行，将socket标记为ESTABLISHED，并且将此socket由 socket queue 移至 established socket queue 中   
(2)客户端的最后一个ack并未来到，超时后内核把 pending socket 移除

- **send 和 recv**
1. send 只是负责拷贝，拷贝完立即返回，不会等待发送和发送之后的 ACK，如果 socket 出现问题，RST 包被反馈回来，在 RST 包返回之时，如果 send 还没有把数据全部放入内核或者发送出去，那么 send 返回-1，errno 被置错误值，如果 RST 包返回之时，send 已经返回，那么RST导致的错误会在下一次 send 或者 recv 调用的时候被立即返回，此次 send 调用所触发的程序错误，可能会在本次返回，也可能在下次调用网络 IO 函数的时候被返回

- **TCP之半关闭与CLOSE_WAIT**
1. 服务器端如果积攒大量的COLSE_WAIT状态的socket，有可能将服务器资源耗尽，进而无法提供服务：一个进程打开一个socket，然后此进程再派生子进程的时候，此socket的sockfd会被继承，socket是系统级的对象，因此socket的引用计数会变成2，调用close(sockfd)时，内核检查此fd对应的socket上的引用计数。如果引用计数大于1，那么将这个引用计数减1，然后返回，如果引用计数等于1，那么内核会真正通过发FIN来关闭TCP连接，调用shutdown(sockfd，SHUT_RDWR)时,内核不会检查此fd对应的socket上的引用计数，直接通过发FIN来关闭TCP连接

- **TCP之TIME_WAIT**
1. TIME_WAIT的作用：    
(1)可靠地实现TCP全双工连接的终止，"主动断开的一方"在发送完最后一次ACK后进入的等待状态，确保"被动断开连接端"可以收到ACK确认消息   
(2)如果主动关闭方不进入TIME_WAIT，如果被动关闭方重传FIN包，这个时候主动关闭方无法识别这个FIN包，回复一个RST包给被动关闭方，被动关闭方就会收到一个错误（connect reset by peer）
(3)允许老的重复分节在网络中消逝，在关闭一个TCP连接后，马上又重新建立起一个相同的IP地址和端口之间的TCP连接，有可能链路上已经关闭的连接的残余数据包影响到新的连接正常的数据包，2*MSL保证任何迟到的报文被丢弃
2. TIME_WAIT带来问题：   
(1)作为服务器，短时间内关闭了大量的Client连接，就会造成服务器上出现大量的TIME_WAIT连接，占据大量的tuple，严重消耗着服务器的资源   
(2)作为客户端，短时间内大量的短连接，会大量消耗的Client机器的端口，毕竟端口只有65535个，端口被耗尽了，后续就无法在发起新的连接了
3. TIME_WAIT快速回收：同时打开 tcp_tw_recycle 和 tcp_timestamps 两个选项
4. TIME_WAIT重用：同时开启tcp_tw_reuse选项和tcp_timestamps 选项（TIME_WAIT重用对Server端来说并没解决大量TIME_WAIT造成的资源消耗的问题，因为不管TIME_WAIT连接是否被重用，它依旧占用着系统资源，即便如此，TIME_WAIT重用还是有些用处的，它解决了整机范围拒绝接入的问题），只要满足下面两点中的一点，一个TW状态的四元组(即一个socket连接)可以重新被新到来的SYN连接使用：   
(1)新连接SYN告知的初始序列号比TIME_WAIT老连接的末序列号大   
(2)如果开启了tcp_timestamps，并且新到来的连接的时间戳比老连接的时间戳大
5. 控制服务器的TIME_WAIT数量：tcp_max_tw_buckets 控制并发的TIME_WAIT的数量，默认值是180000，如果超过默认值，内核会把多的TIME_WAIT连接清掉，然后在日志里打一个警告

- **ACK时延确认和Nagle算法**
1. ACK时延确认：通常TCP在接收到数据时并不立即发送ACK，相反，它推迟发送，以便将ACK与需要沿该方向发送的数据一起发送
2. TCP交互数据的报文段数据利用率低，在网络环境不好的情况下容易加重网络负担，nagle算法的核心思想是允许网络中最多只能有一个小分组被发送，而待发送的其它小分组会被重新分组成一个"较大的"小分组，等收到上一个小分组的应答后再发送，nagle算法可以减少网络中微小分组的数量，对于交互性很强的应用程序可以使用TCP_NODELAY选项可以禁止Negale 算法

- **TCP粘包**
1. 粘包问题：   
(1)tcp每次发送数据，就与对方建立连接，然后双方发送完一段数据后，就关闭连接，不会出现粘包问题   
(2)发送数据无结构，如文件传输，这样发送方只管发送，接收方只管接收存储就ok，也不用考虑粘包   
(3)双方建立连接，需要在连接后一段时间内发送不同结构数据，如连接后，有好几种结构，需要处理粘包问题
2. 粘包的原因：   
(1)TCP是个数据"流"协议，即没有界限的一串数据，UDP是基于报文发送的，首部采用了16bit来指示UDP数据报文的长度，UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）   
(2)发送端需要等缓冲区满才发送出去，造成粘包（Nagle算法）   
(3)接收方不及时接收缓冲区的包，造成多个包接收粘包   
3. 如何封包和拆包：   
(1)封包就是给一段数据加上包头，数据包就分为包头和包体两部分，包头包含了表示包体的长度   
(2)拆包：为每一个连接动态分配一个缓冲区，当接收到数据时首先把此段数据存放在缓冲区中，判断缓存区中的数据长度是否够一个包头的长度,如不够,则不进行拆包操作，根据包头数据解析出里面代表包体长度的变量，判断缓存区中除包头外的数据长度是否够一个包体的长度,如不够,则不进行拆包操作，取出整个数据包（缺点：缓冲区需要分配内存，多了一些内存拷贝操作）   
(3)利用底层的缓冲区来进行拆包或者recv我们要接收多长长度的数据

- **滑动窗口**
1. 滑动窗口实现了TCP流控制，解决因接收端和发送端对数据包的处理速度不同的会造成接收端数据溢出等问题
2. 发送窗口：   
(1)已发送，已收到ACK   
(2)已发送，未收到ACK   
(3)未发送，但接收方允许发送   
(4)未发送，但接收方不允许发送
3. 接收窗口：   
(1)已接收，未被应用层处理   
(2)已接收，未回复ACK   
(3)空闲缓冲区接收数据   
4. 发送窗口：接收方允许发送方一次能容纳的未确认的字节数
5. 累计确认机制：接收方会发送自上一次成功接收后的最长字节数
5. 滑动窗口机制：发送方不必发送一个全窗口大小的数据，确认来自报文段的ACK把窗口向右滑动，接收方缓冲区可接收数据减少会使窗口不可向右滑动，接收方可以延迟发送ACK，遵循快速重传、累计确认、选择确认等规则

- **超时重传**
1. 如果重传定时器溢出时还没收到确认信号，则重传该数据
2. RTT(Round Trip Time)：一个连接的往返时间，即数据发送时刻到接收到确认的时刻的差值
3. RTO(Retransmission Time Out)：重传超时时间，即从数据发送时刻算起，超过这个时间便执行重传
4. RTT和RTO 的关系是：由于网络波动的不确定性，每个RTT都是动态变化的，所以RTO也应随着RTT动态变化
5. 包含数据的片段一经发送，片段的一份复制就放在重传队列并启动重传计时器，队列按照重传计时器的剩余时间来排列，如果在计时器超时之前收到了确认信息，则该片段从重传队列中移除，如果在计时器超时之前没有收到确认信息，则发生重传超时，片段自动重传并重置重传定时器，TCP只会重传一定数量的次数，并判断出现故障终止连接

- **TCP选择确认SACK**
1. TCP收到乱序数据后，使用SACK选项可以告知发包方收到了哪些数据，发包方收到这些信息后就会知道哪些数据丢失，然后立即重传丢失的部分
2. Left Edge of Block：不连续块的第一个数据的序列号，Right Edge of Block：不连续块的最后一个数据的序列号之后的序列号
3. tcp首部中的选项部分最大是40字节，左边界和右边界在指明一个数据块时就用掉了8字节，指明4个数据块就用掉了32字节，再加上Length两个字段占用的2字节，因此TCP选项的选择确认选项最多也就只能指明4个数据块

- **TCP的拥塞控制**
1. 拥塞控制就是防止过多的数据注入网络中，这样可以使网络中的路由器或链路不致过载，拥塞控制是一个全局性的过程，和流量控制不同，流量控制指点对点通信量的控制
2. 慢开始与拥塞避免：发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量，拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化，为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量
3. 慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小，当cwnd<ssthresh时，使用慢开始算法，当cwnd>ssthresh时，改用拥塞避免算法"加法增大"，当cwnd=ssthresh时，慢开始与拥塞避免算法任意
4. 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限设置为出现拥塞时的发送窗口大小的一半，即"乘法减小"算法，然后把拥塞窗口设置为1，执行慢开始算法
5. 快重传：快重传算法要求首先接收方收到一个失序的报文段后就立刻发出重复确认，如果接收方一连收到三个重复的ACK,那么发送方不必等待重传计时器到期，由于发送方尽早重传未被确认的报文段
6. 快恢复：当发送发连续接收到三个确认时，就执行乘法减小算法，把慢启动开始门限（ssthresh）减半，但是接下来并不执行慢开始算法，而是把cwnd设置为ssthresh的一半，然后执行拥塞避免算法，使拥塞窗口缓慢增大

- **坚持定时器**
1. 当TCP服务器收到了客户端的0滑动窗口报文的时候，就启动一个定时器来计时，并在定时器溢出的时候向向客户端查询窗口是否已经增大，如果得到非零的窗口就重新开始发送数据，如果得到0窗口就再开一个新的定时器准备下一次查询

- **糊涂窗口综合症**
1. 接收端和发送端速率不匹配的状况下，当客户端通告一个小的非零窗口时，服务器立刻发送小数据给客户端并充满其缓冲区，一来二去就会让网络中充满小TCP数据报，从而影响网络利用率
2. TCP规定：   
(1)接收方不通告小窗口，通常的算法是接收方不通告一个比当前窗口大的窗口（可以为0），除非窗口可以增加一个报文段大小（也就是将要接收的MSS）或者可以增加接收方缓存空间的一半，不论实际有多少   
(2)发送方避免出现糊涂窗口综合症的措施是只有以下条件之一满足时才发送数据：可以发送一个满长度的报文段，可以发送至少是接收方通告窗口大小一半的报文段，可以发送任何数据并且不希望接收ACK（也就是说，我们没有还未被确认的数据）或者该连接上
不能使用Nagle算法
3. TCP的很多规定都是为了在一次传送中发送尽量多的数据，例如捎带ACK数据报文的策略，累计ACK，延迟ACK，Nagle算法，重传时发送包含原数据报文的策略等等

- **保活定时器**
1. 定时发送探测报文，探测对端是否还活着，防止资源被白白占用

---

> [网络协议](https://blog.csdn.net/china_jeffery/category_9271154.html)   
> [TCP/IP详解 卷1：协议](http://www.52im.net/topic-tcpipvol1.html)   
> [理解TCP序列号和确认号](https://blog.csdn.net/a19881029/article/details/38091243)

> [TCP粘包分析](https://blog.csdn.net/zhangxinrun/article/details/6721495?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)   
> [TCP粘包拆包及解决方法](https://blog.csdn.net/Scythe666/article/details/51996268?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

> [滑动窗口](https://blog.csdn.net/wdscq1234/article/details/52444277?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)   
> [解析TCP之滑动窗口](https://blog.csdn.net/yao5hed/article/details/81046945?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

> [TCP的拥塞控制](https://blog.csdn.net/sicofield/article/details/9708383?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)   
> [TCP拥塞控制-慢启动、拥塞避免、快重传、快启动](https://blog.csdn.net/jtracydy/article/details/52366461?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

> [TCP/IP详解学习笔记(13)-TCP坚持定时器，TCP保活定时器](https://blog.csdn.net/goodboy1881/article/details/758034?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)   
> [TCP-IP详解：糊涂窗口综合症](https://blog.csdn.net/wdscq1234/article/details/52463952)

> [深入浅出TCP](http://blog.chinaunix.net/uid/29075379/cid-181331-list-4.html)

> [浅析TCP协议中的疑难杂症(上篇)](http://www.52im.net/thread-1003-1-1.html)   
> [浅析TCP协议中的疑难杂症(下篇)](http://www.52im.net/thread-1004-1-1.html)

---
## 抓包

- **抓包实例诊断TCP连接问题**
1. 三重SYN信息而没有响应：可能是由于不被防火墙允许，或服务器发生故障
2. SYN信息带一个reset(RST)响应：防火墙拦截了端口6036，或如果配置了端口地址转换（PAT），那么仅转换端口80而非6036
3. 永远记住确认一下是否有NAT，端口转发，以及涉及TCP和UDP端口的机制，这些机制可能会中断TCP正常操作

- **抓包实例分析TCP重传**
1. 重传至多个目的地址（多台服务器）：有多次重传，分布于多台服务器，目的端口都一致，因此报文是丢失在发往Internet的途中，或确认信息没有及时从web服务器发回
2. 重传至单一连接：所有重传发生于同一IP，同一TCP端口号，链路负载较高或者慢速软件响应问题引起的重传
3. 应用无响应导致重传：客户端或服务器没有响应请求这种情况下，五次重传，时间也会逐渐延长，会发送reset来关闭连接，断开连接之后，可能会发生两件事情：   
(1)发送SYN请求至客户端，以打开一个新的连接，这种情况下用户会看到应用冻结，过了15-20秒之后重新开始工作   
(2)不发送SYN，用户需要重新运行应用程序
4. 由于延时变化导致重传，检查延时变量，可能由以下原因引起：   
(1)不稳定或繁忙通信链路引起，这种情况下，可以看到ping命令的延时变化，通常由于带宽较窄   
(2)应用过载或资源不足，这种情况下，只有该应用发生很多重传   
(3)通信设备过载（CPU,缓存）引起延时，检查方式直接连接通信设备

- **抓包实例分析TCP重复ACK与乱序**
1. 当重复ACK的数量保持在合理范围时，即1或2个百分比，则可能不是本机问题
2. 当有大量的重复ACK时（假设有10个），则可能是通信链路繁忙引起延迟改变或者服务器或客户端无响应
3. 快重传ACK减少了发往网络的吞吐量
4. 收到乱序的报文

- **抓包实例分析TCP窗口**
1. TCP零窗口：应用碰到没有足够内存的问题，因此TCP需告知发送方停止发送数据或应用消耗太多内存因此操作系统要限制应用资源
2. TCP窗口违例：某一应用报出常规应用错误

- **抓包实例分析TCP reset**
1. 无故障时发送reset：web打开一个网页可能同时打开了数十个连接，要关闭所有这些有时需要数百个FIN和FIN-ACK报文，为了防止其发生，web服务器在很多情况下会在发送请求数据之后用reset断开连接
2. 有故障时发送reset：   
(1)防火墙发送的reset，发送的每一个SYN都返回以RST   
(2)五个连续没有收到ACK回复的重传，发送一个reset信号到对端告知其断开连接

> [网络基本功](https://blog.csdn.net/qq_38111600/category_7799440.html)


---
## TCP选项

- **TCP选项之SO_REUSEADDR**
1. 服务器进程挂掉（内核自动关闭所有此进程打开的文件，其中包括socket），监听socket进入TIME_WAIT状态（此时socket仍存在于系统中），重新启动服务器，如果在监听前没有对监听socket设置此选项，此时会导致bind调用失败

- **TCP选项之SO_LINGER**
1. close()关闭TCP连接时的行为：   
(1)缺省close()的行为：如果有数据残留在socket发送缓冲区中则系统将继续发送这些数据给对方，等待被确认，然后返回   
(2)立即关闭该连接，通过发送RST分组来关闭该连接，发送缓冲区中如果有未发送完的数据则丢弃   
(3)将连接的关闭设置一个超时，如果socket发送缓冲区中仍残留数据，进程进入睡眠，内核进入定时状态去尽量去发送这些数据，超时后用RST关闭连接

```
struct linger {
     int l_onoff;
     int l_linger;
};

l_onoff为0，则该选项关闭，l_linger的值被忽略，close()用上述缺省方式关闭连接
l_onoff非0，l_linger为0，close()用上述(2)方式关闭连接
l_onoff非0，l_linger非0，close()用上述(3)方式关闭连接
```

- **TCP选项之TCP_CORK和TCP_NODELAY**
1. CORK：尽量向发送缓冲区中攒数据，攒到多了再发送，这样网络的有效负载会升高
2. NODELAY：禁止 Negale 算法，只要发送缓冲区中有数据，并且发送窗口是打开的，就尽量把数据发送到网络上去

- **TCP选项之SO_RCVBUF和SO_SNDBUF**
1. 设置 socket read/write 缓冲区

- **TCP选项之SO_RCVLOWAT和SO_SNDLOWAT**
1. 接收低潮限度：对于TCP套接口而言，接收缓冲区中的数据必须达到规定数量，内核才通知进程"可读"，如触发select或者epoll
2. 发送低潮限度：发送缓冲区中的数据必须达到规定数量，内核才发送数据

> [TCP之深入浅出](http://blog.chinaunix.net/uid/29075379/list/1.html?cid=181331)

---
## 不为人知的网络编程

- **RUDP 主要解决的问题**
1. 端对端连通性问题：一般终端直接和终端通信都会涉及到 NAT 穿越，TCP 在 NAT 穿越实现非常困难，相对来说 UDP 穿越 NAT 却简单很多，如果是端到端的可靠通信一般用 RUDP 方式来解决，场景有：端到端的文件传输、实时音视频传输、交互指令传输等等
2. 弱网环境传输问题：在一些 Wi-Fi 或者 3G/4G 移动网下，需要做低延迟可靠通信，如果用 TCP 通信延迟可能会非常大，这会影响用户体验。例如：实时的操作类网游通信、语音对话、多方白板书写等，这些场景可以采用特殊的 RUDP 方式来解决这类问题
3. 带宽竞争问题：有时候客户端数据上传需要突破本身 TCP 公平性的限制来达到高速低延时和稳定，也就是说要用特殊的流控算法来压榨客户端上传带宽，例如：直播音视频推流，这类场景用 RUDP 来实现不仅能压榨带宽，也能更好地增加通信的稳定性，避免类似 TCP 的频繁断开重连
4. 传输路径优化问题：在一些对延时要求很高的场景下，会用应用层 relay 的方式来做传输路由优化，也就是动态智能选路，这时双方采用 RUDP 方式来传输，中间的延迟进行 relay 选路优化延时，还有一类基于传输吞吐量的场景，例如：服务与服务之间数据分发、数据备份等，这类场景一般会采用多点并联 relay 来提高传输的速度，也是要建立在 RUDP 上的（这两点在后面着重来描述）
5. 资源优化问题：某些场景为了避免 TCP 的三次握手和四次挥手的过程，会采用 RUDP 来优化资源的占用率和响应时间，提高系统的并发能力，例如 QUIC

- **RUDP 通过重传实现可靠**
1. 定时重传：   
(1)在 RTO 时间内超时还未收到这个数据包的 ACK 消息，那么发送端就重传这个数据包   
(2)容易出现对方收到了数据包，但是 ACK 发送途中丢失和ACK 在途中，但是发送端的时间已经超过了一个 RTO 的误判   
(3)适用场景：一个对延迟敏感但对流量成本要求不高的场景，可以将 RTO 的计算设计得比较小能尽最大可能保证你的延时足够小，例如：实时操作类网游、教育领域的书写同步
2. 请求重传：   
(1)接收端在发送 ACK 的时候携带自己丢失报文的信息反馈，发送端接收到 ACK 信息时根据丢包反馈进行报文重传   
(2)因为 UDP 在网络传输过程中会乱序会抖动，接收端在通信的过程中要评估网络的振动时间（jitter time），当发现丢包的时候，后续的 ACK 就需要携带这个丢包信息   
(3)这种方式是由丢包请求引起的重发，如果网络很不好，接收端会不断发起重传请求，造成发送端不停的重传，引起网络风暴，通信质量会下降，所以我们在发送端设计一个拥塞控制模块来限流   
(4)整个请求重传机制依赖于 jitter time 和 RTO 这个两个时间参数，评估和调整这两个参数和对应的传输场景也息息相关，请求重传这种方式比定时重传方式的延迟会大，一般适合于带宽较大的传输场景，例如：视频、文件传输、数据同步等
3. FEC 分组方式选择重传：   
(1) FEC（Forward Error Correction）是一种前向纠错技术，一般通过 XOR 类似的算法来实现，其实是一个解方程的过程   
(2)在发送方发送报文的时候，会根据 FEC 方式把几个报文进行 FEC 分组，通过 XOR 的方式得到若干个冗余包，然后一起发往接收端，如果接收端发现丢包但能通过 FEC 分组算法还原，就不向发送端请求重传，如果分组内包是不能进行 FEC 恢复的，就向发送端请求原始的数据包   
(3)FEC 分组方式适合解决要求延时敏感且随机丢包的传输场景，在一个带宽不是很充裕的传输条件下，FEC 会增加多余的包，可能会使得网络更加不好，FEC 方式不仅可以配合请求重传模式，也可以配合定时重传模式
4. 窗口：如果涉及到可靠有序的 RUDP，接收端就要做窗口排序和缓冲，如果是无序可靠或者尽力可靠的场景，接收端一般就不做窗口缓冲，只做位置滑动
5. 经典拥塞算法：慢启动、拥塞避免、拥塞处理、快速恢复

> [不为人知的网络编程](http://www.52im.net/thread-1003-1-1.html)


---
## Http
- **Http请求**
1. 由请求行、消息报头、请求正文组成

- **Http响应**
1. 由状态行、消息报头、响应正文组成
2. 状态码：   
(1)1xx：指示信息--表示请求已接收，继续处理   
(2)2xx：成功--表示请求已被成功接收、理解、接受   
(3)3xx：重定向--要完成请求必须进行更进一步的操作   
(4)4xx：客户端错误--请求有语法错误或请求无法实现   
(5)5xx：服务器端错误--服务器未能实现合法的请求

- **Http1.0和Http1.1区别**
1. HTTP1.0每对Request/Response都使用一个新的连接，HTTP 1.1支持持久连接，在同一个tcp的连接中可以传送多个HTTP请求和响应
2. 在HTTP 1.1中增加Host请求头字段后，Web浏览器可以使用主机头名来明确表示要访问服务器上的哪个Web站点，这才实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点

- **Http1.x**
1. 缺陷：线程阻塞，在同一时间，同一域名的请求有一定数量限制，超过限制数目的请求会被阻塞

- **http1.0**
1. 缺陷：浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接（TCP连接的新建成本很高，因为需要客户端和服务器三次握手），服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求
2. 解决方案：添加头信息——非标准的Connection字段Connection: keep-alive

- **http1.1**
1. 持久连接：引入了持久连接，即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive(对于同一个域名，大多数浏览器允许同时建立6个持久连接)
2. 管道机制：即在同一个TCP连接里面，客户端可以同时发送多个请求
3. 分块传输编码：即服务端没产生一块数据，就发送一块，采用"流模式"而取代"缓存模式"
4. 缺点：虽然允许复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的，服务器只有处理完一个请求，才会接着处理下一个请求，如果前面的处理特别慢，后面就会有许多请求排队等着，这将导致"队头堵塞"

- **HTTP/2.0**
1. 二进制协议：HTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制，HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"：头信息帧和数据帧
2. 完全多路复用：HTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了"队头堵塞"
3. 报头压缩：HTTP 协议是没有状态，导致每次请求都必须附上所有信息，所以，请求的很多头字段都是重复的，比如Cookie，HTTP/2 对这一点做了优化，引入了头信息压缩机制，一方面，头信息使用gzip或compress压缩后再发送，另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，产生一个索引号，之后就不发送同样字段了，只需发送索引号
4. 服务器推送：HTTP/2 允许服务器未经请求，主动向客户端发送资源，通过推送那些服务器任务客户端将会需要的内容到客户端的缓存中，客户端也可以选择发送一个 RST_STREAM frame 拒绝任何它不想要的资源

- **HTTPS**
1. HTTP协议通常承载于TCP协议之上，在HTTP和TCP之间添加一个安全协议层（SSL或TSL）
2. HTTPS主要作用：对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全，并对网站服务器进行真实身份认证
3. HTTPS和HTTP的区别：   
(1)HTTPS是加密传输协议，HTTP是名文传输协议   
(2)HTTPS需要用到SSL证书，而HTTP不用   
(3)HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO   
(4)HTTPS标准端口443，HTTP标准端口80   
(5)HTTPS基于传输层，HTTP基于应用层
4. SSL 包含动作：   
(1)验证服务器端   
(2)客户端和服务器端选择加密算法和密码，确保双方都支持
(3)验证客户端(可选)   
(4)使用公钥加密技术来生成共享加密数据   
(5)创建一个加密的 SSL 连接   
(6)基于该 SSL 连接传递 HTTP 请求
5. HTTPS加密方式：   
(1)对称加密：加密和解密都是使用的同一个密钥   
(2)非对称加密：加密使用的密钥和解密使用的密钥是不相同的，分别称为：公钥、私钥，公钥和算法都是公开的，私钥是保密的   
(3)非对称加密过程：   
&emsp;a)服务端生成配对的公钥和私钥   
&emsp;b)私钥保存在服务端，公钥发送给客户端   
&emsp;c)客户端使用公钥加密明文传输给服务端   
&emsp;d)服务端使用私钥解密密文得到明文   
(4)数字签名：签名就是在信息的后面再加上一段内容，可以证明信息没有被修改过

- **HTTPS的加密过程**
1. 对称密钥加密：加密和解密同用一个密钥
2. 非对称密钥加密：发送密文的一方使用公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密
3. 如何证明公开密钥本省是货真价实的公开密钥：可以使用由数字证书认证机构（CA，Certificate Authority）和其他相关机关颁发的公开密钥证书，接收到证书的客户端可以使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可以明确认证服务器的公开密钥的是真实有效的数字证书认证机构以及服务器的公开密钥是值得信赖的

- **HTTPS的安全通信机制**
1. 认证服务器：浏览器内置一个受信任的CA机构列表，并保存了这些CA机构的证书，第一阶段服务器会提供经CA机构认证颁发的服务器证书，如果认证该服务器证书的CA机构，存在于浏览器的受信任CA机构列表中，并且服务器证书中的信息与当前正在访问的网站（域名等）一致，那么浏览器就认为服务端是可信的，并从服务器证书中取得服务器公钥
2. 协商会话密钥：客户端在认证完服务器，获得服务器的公钥之后，利用该公钥与服务器进行加密通信，协商出两个会话密钥，分别是用于加密客户端往服务端发送数据的客户端会话密钥和用于加密服务端往客户端发送数据的服务端会话密钥，在已有服务器公钥，可以加密通讯的前提下，还要协商两个对称密钥的原因，是因为非对称加密相对复杂度更高，在数据传输过程中，使用对称加密，可以节省计算资源，另外，会话密钥是随机生成，每次协商都会有不一样的结果，所以安全性也比较高
3. 加密通讯：此时客户端服务器双方都有了本次通讯的会话密钥，之后传输的所有Http数据，都通过会话密钥加密，这样网路上的其它用户，将很难窃取和篡改客户端和服务端之间传输的数据，从而保证了数据的私密性和完整性

- **HTTPS的通信步骤**
1. TCP的三次握手，客户端通过发送Client Hello报文开始SSL通信，报文中包含客户端支持的SSL的指定版本、加密组件列表（所使用的加密算法及密钥长度等）
2. 服务器可进行SSL通信时，会以Server Hello报文作为应答，和客户端一样，在报文中包含SSL版本以及加密组件，服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的
3. 之后服务器发送Certificate报文，报文中包含公开密钥证书
4. 最后服务器发送Server Hello Done 报文通知客户端，最初阶段的SSL握手协商部分结束
5. 客户端验证证书有效性
6. SSL第一次握手结束之后，客户端以Client Key Exchange报文作为回应，报文中包含通信加密中使用的一种被称为Pre-master secret的随机密码串，该报文已用步骤3中的公开密钥进行加密
7. 接着客户端继续发送Change Cipher Spec报文，该报文会提示服务器，在此报文之后的通信会采用Pre-master secret密钥加密
8. 客户端发送Finished报文，该报文包含连接至今全部报文的整体校验值，这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准
9. 服务器同样发送Change Cipher Spec报文
10. 服务器同样发送Finshed报文
11. 服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成，当然，通信会受到SSL的保护，从此处开始进行应用层协议的通信，即发送HTTP请求

> [HTTP协议详解](https://www.cnblogs.com/li0803/archive/2008/11/03/1324746.html)   
> [http1.0 和http1.1 区别](https://blog.csdn.net/hguisu/article/details/8608888)   
> [深入理解http1.x、http 2和https](https://segmentfault.com/a/1190000015316332)

> [HTTPS的加密过程](https://blog.csdn.net/qq_32998153/article/details/80022489)

---
## cookie、session id、token

- **session**
1. HTTP是无状态的，通过给客户端发送session id，后续客户端发起请求的时候把session id捎带过去，服务端通过这个session id 管理会话（seesion id 对无服务端来说是巨大的开销）

- **token**
1. 客户端通过加密算法和密钥对数据生成一个token发给服务端
2. 服务端用相同的方式生成token，与客户端传递的token做对比

- **cookie**
1. cookie由服务端生成，发送给浏览器，浏览器把cookie以kv形式保存到某个文件下，下次请求同一个网站会把cookie发送给服务端

> [cookie、session、token](https://www.cnblogs.com/moyand/p/9047978.html)
---
## netfilter/iptables简介

- **netfilter和iptables**
1. netfilter特指内核中的netfilter框架，iptables指用户空间的配置工具
2. netfilter在协议栈中添加了5个钩子，允许内核模块在这些钩子的地方注册回调函数，这样经过钩子的所有数据包都会被注册在相应钩子上的函数所处理，包括修改数据包内容、给数据包打标记或者丢掉数据包等
3. netfilter框架负责维护钩子上注册的处理函数或者模块，以及它们的优先级
4. iptables是用户空间的一个程序，通过netlink和内核的netfilter框架打交道，负责往钩子上配置回调函数

- **netfilter钩子（hooks）**

```
// 在内核协议栈中，有5个跟netfilter有关的钩子，数据包经过每个钩子时，都会检查上面是否注册有函数，如果有的话，就会调用相应的函数处理该数据包
// 注意：netfilter所有的钩子（hooks）都是在内核协议栈的IP层

         |
         | Incoming
         ↓
+-------------------+
| NF_IP_PRE_ROUTING |
+-------------------+
         |
         |
         ↓
+------------------+
|                  |         +----------------+
| routing decision |-------->| NF_IP_LOCAL_IN |
|                  |         +----------------+
+------------------+                 |
         |                           |
         |                           ↓
         |                  +-----------------+
         |                  | local processes |
         |                  +-----------------+
         |                           |
         |                           |
         ↓                           ↓
 +---------------+          +-----------------+
 | NF_IP_FORWARD |          | NF_IP_LOCAL_OUT |
 +---------------+          +-----------------+
         |                           |
         |                           |
         ↓                           |
+------------------+                 |
|                  |                 |
| routing decision |<----------------+
|                  |
+------------------+
         |
         |
         ↓
+--------------------+
| NF_IP_POST_ROUTING |
+--------------------+
         |
         | Outgoing
         ↓
         

// NF_IP_PRE_ROUTING：接收的数据包刚进来，还没有经过路由选择，即还不知道数据包是要发给本机还是其它机器
// NF_IP_LOCAL_IN：已经经过路由选择，并且该数据包的目的IP是本机，进入本地数据包处理流程
// NF_IP_FORWARD：已经经过路由选择，但该数据包的目的IP不是本机，而是其它机器，进入forward流程
// NF_IP_LOCAL_OUT：本地程序要发出去的数据包刚到IP层，还没进行路由选择
// NF_IP_POST_ROUTING：本地程序发出去的数据包，或者转发（forward）的数据包已经经过了路由选择，即将交由下层发送出去

// 一个数据包只会经过下面三个路径中的一个：
// 本机收到目的IP是本机的数据包：NF_IP_PRE_ROUTING -> NF_IP_LOCAL_IN
// 本机收到目的IP不是本机的数据包：NF_IP_PRE_ROUTING -> NF_IP_FORWARD -> NF_IP_POST_ROUTING
// 本机发出去的数据包：NF_IP_LOCAL_OUT -> NF_IP_POST_ROUTING
```

- **iptables中的表（tables）**
1. iptables用表（table）来分类管理它的规则（rule），其中rule就是应用在netfilter钩子上的函数，用来修改数据包的内容或过滤数据包，目前iptables支持的表有下面这些规则：   
(1)Filter：主要用来过滤数据，用来控制让哪些数据可以通过，哪些数据不能通过，它是最常用的表   
(2)NAT：用来处理网络地址转换的，控制要不要进行地址转换，以及怎样修改源地址或目的地址，从而影响数据包的路由，达到连通的目的   
(3)Mangle：主要用来修改IP数据包头，比如修改TTL值，同时也用于给数据包添加一些标记   
(4)Raw：主要用来追踪所有的连接，而raw表里的rule的功能是给数据包打标记，从而控制哪些数据包不被connection tracking所追踪   
(5)Security：要是在数据包上设置一些SELinux的标记，便于跟SELinux相关的模块来处理该数据包  
2. 每条rule包含下面两部分信息：   
(1)Matching：如何匹配一个数据包，匹配条件很多，比如协议类型、源/目的IP、源/目的端口、in/out接口、包头里面的数据以及连接状态等   
(2)Targets：Targets就是找到匹配的数据包之后怎么办，DROP直接将数据包丢弃，RETURN跳出当前chain，QUEUE将数据包放入用户空间的队列供用户空间的程序处理，ACCEPT同意数据包通过继续执行后续的rule

- **chains**
1. iptables将表中的rule继续分类，让rule属于不同的链（chain），由chain来决定什么时候触发chain上的这些rule

```
                                    |
                                    | Incoming             ++---------------------++
                                    ↓                      || raw                 ||
                           +-------------------+           || connection tracking ||
                           | NF_IP_PRE_ROUTING |= = = = = =|| mangle              ||
                           +-------------------+           || nat (DNAT)          ||
                                    |                      ++---------------------++
                                    |
                                    ↓                                                ++------------++
                           +------------------+                                      || mangle     ||
                           |                  |         +----------------+           || filter     ||
                           | routing decision |-------->| NF_IP_LOCAL_IN |= = = = = =|| security   ||
                           |                  |         +----------------+           || nat (SNAT) ||
                           +------------------+                 |                    ++------------++
                                    |                           |
                                    |                           ↓
                                    |                  +-----------------+
                                    |                  | local processes |
                                    |                  +-----------------+
                                    |                           |
                                    |                           |                    ++---------------------++
 ++------------++                   ↓                           ↓                    || raw                 ||
 || mangle     ||           +---------------+          +-----------------+           || connection tracking ||
 || filter     ||= = = = = =| NF_IP_FORWARD |          | NF_IP_LOCAL_OUT |= = = = = =|| mangle              ||
 || security   ||           +---------------+          +-----------------+           || nat (DNAT)          ||
 ++------------++                   |                           |                    || filter              ||
                                    |                           |                    || security            ||
                                    ↓                           |                    ++---------------------++
                           +------------------+                 |
                           |                  |                 |
                           | routing decision |<----------------+
                           |                  |
                           +------------------+
                                    |
                                    |
                                    ↓
                           +--------------------+           ++------------++
                           | NF_IP_POST_ROUTING |= = = = = =|| mangle     ||
                           +--------------------+           || nat (SNAT) ||
                                    |                       ++------------++
                                    | Outgoing
                                    ↓
                                    

// iptables里面有5个内置的chains，分别对应5个钩子：
// PREROUTING：数据包经过NF_IP_PRE_ROUTING时会触发该chain上的rule
// INPUT：数据包经过NF_IP_LOCAL_IN时会触发该chain上的rule
// FORWARD：数据包经过NF_IP_FORWARD时会触发该chain上的rule
// OUTPUT：数据包经过NF_IP_LOCAL_OUT时会触发该chain上的rule
// POSTROUTING：数据包经过NF_IP_POST_ROUTING时会触发该chain上的rule
```

> [netfilter/iptables简介](https://segmentfault.com/a/1190000009043962)

---
## 面试

- **TCP/UDP的区别**
1. TCP面向连接，UDP面向非连接即发送数据前不需要建立链接
2. TCP提供可靠的服务（数据传输），UDP无法保证
3. TCP面向字节流，UDP面向报文
4. TCP数据传输比UDP慢
5. 在一个TCP连接中，仅有两方进行彼此通信，因此广播和多播不能用于TCP
6. TCP使用校验和，确认和重传机制，累积确认，来保证可靠传输，使用滑动窗口机制来实现流量控制

- **TCP协议如何来保证传输的可靠性**
1. 数据包校验
2. 对失序数据包重排序
3. 丢弃重复数据
4. 确认ACK机制
5. 超时重发
6. 流量控制

- **在浏览器中输入 www.baidu.com 后执行的全部过程**
1. 客户端浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径，客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层
2. 在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口
3. 网络层主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，无非就是通过查找路由表决定通过那个路径到达服务器
4. 客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址

- 单台服务器并发TCP连接数到底可以有多少
1. 文件句柄限制：   
(1)进程限制：执行 ulimit -n 输出 1024，说明对于一个进程而言最多只能打开1024个文件   
(2)全局限制：cat /proc/sys/fs/file-nr 输出 9344 0 592026（已经分配的文件句柄数，已经分配但没有使用的文件句柄数，最大文件句柄数）
2. 四元组来唯一标识一个TCP连接：{local ip, local port,remote ip,remote port}，最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为2^32（ip数） * 2^16（port数）

> [计算机网络面试问题集锦](https://blog.csdn.net/qq_39322743/article/details/79700863)   
> [单台服务器并发TCP连接数到底可以有多少](http://www.52im.net/thread-561-1-1.html)
